{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://cognitiveclass.ai/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork20647850-2021-01-01\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/Logos/organization_logo/organization_logo.png\" width = 400> </a>\n",
    "\n",
    "<h1 align=center><font size = 5>Pre-Trained Models</font></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Objective\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3> \n",
    "\n",
    "1.  <a href=\"https://#item31\">Import Libraries and Packages</a>\n",
    "2.  <a href=\"https://#item32\">Download Data</a>\n",
    "3.  <a href=\"https://#item33\">Define Global Constants</a>\n",
    "4.  <a href=\"https://#item34\">Construct ImageDataGenerator Instances</a>\n",
    "5.  <a href=\"https://#item35\">Compile and Fit Model</a>\n",
    "\n",
    "</font>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item31'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Import Libraries and Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's start the lab by importing the libraries that we will be using in this lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet import ResNet101\n",
    "from tensorflow.keras.applications.resnet import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item32'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Download Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "For your convenience, I have placed the data on a server which you can retrieve easily using the **wget** command. So let's run the following line of code to get the data. Given the large size of the image dataset, it might take some time depending on your internet speed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now if you check the left directory pane, you should see the zipped file *concrete_data_week3.zip* appear. So, let's go ahead and unzip the file to access the images. Given the large number of images in the dataset, this might take a couple of minutes, so please be patient, and wait until the code finishes running.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the folder *concrete_data_week3* appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: *train* and *valid*. And if you explore these folders, you will find that each contains two subfolders: *positive* and *negative*. These are the same folders that we saw in the labs in the previous modules of this course, where *negative* is the negative class and it represents the concrete images with no cracks and *positive* is the positive class and it represents the concrete images with cracks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the *negative* and *positive* folders. This may consume all of your memory and you may end up with a **50**\\* error. So please **DO NOT DO IT**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item33'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Define Global Constants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here, we will define constants that we will be using throughout the rest of the lab.\n",
    "\n",
    "1.  We are obviously dealing with two classes, so *num_classes* is 2.\n",
    "2.  The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
    "3.  We will training and validating the model using batches of 100 images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "image_resize = 224\n",
    "\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item34'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Construct ImageDataGenerator Instances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will use the *flow_from_directory* method to get the training images as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2401 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'horse2zebra/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Your Turn**: Use the *flow_from_directory* method to get the validation images and assign the result to **validation_generator**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 260 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Type your answer here\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'horse2zebra/test',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Double-click **here** for the solution.\n",
    "\n",
    "<!-- The correct answer is:\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item35'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Build, Compile and Fit Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this section, we will start building our model. We will use the Sequential model class from Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument *include_top* and set it to **False**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "171450368/171446536 [==============================] - 30s 0us/step\n",
      "171458560/171446536 [==============================] - 30s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model.add(ResNet101(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the model's layers using the *layers* attribute of our model object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.functional.Functional at 0x7fae9431ea20>,\n",
       " <keras.layers.core.Dense at 0x7faeb7b7a828>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the ResNet50 layers by running the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7faf683227f0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7faeb420ca58>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb420cbe0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb41ec048>,\n",
       " <keras.layers.core.Activation at 0x7faeb41a4860>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7faeb4149c18>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7faeb4153780>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb41620f0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb415d898>,\n",
       " <keras.layers.core.Activation at 0x7faeb40fb2b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb4102d68>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb41134e0>,\n",
       " <keras.layers.core.Activation at 0x7faeb4113b00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb415d240>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb411bd68>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb415dc18>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb40b3438>,\n",
       " <keras.layers.merge.Add at 0x7faeb40b3278>,\n",
       " <keras.layers.core.Activation at 0x7faeb40caf60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb40caeb8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb40d7c18>,\n",
       " <keras.layers.core.Activation at 0x7faeb40ca7f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb4121240>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb4121f28>,\n",
       " <keras.layers.core.Activation at 0x7faeb40b3518>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb4113358>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb416afd0>,\n",
       " <keras.layers.merge.Add at 0x7faeb416a908>,\n",
       " <keras.layers.core.Activation at 0x7faeb40debe0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb40decf8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb4137d68>,\n",
       " <keras.layers.core.Activation at 0x7faeb40dec88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb4070f60>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb4084ac8>,\n",
       " <keras.layers.core.Activation at 0x7faeb408a0f0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb4092d68>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb40a9908>,\n",
       " <keras.layers.merge.Add at 0x7faeb40a3c88>,\n",
       " <keras.layers.core.Activation at 0x7faeb4038c88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb403e240>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb4038780>,\n",
       " <keras.layers.core.Activation at 0x7faeb4058470>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb406aeb8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb406a278>,\n",
       " <keras.layers.core.Activation at 0x7faeb4054208>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb40387b8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb4054278>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb40925f8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb40a3b70>,\n",
       " <keras.layers.merge.Add at 0x7faeb404b438>,\n",
       " <keras.layers.core.Activation at 0x7faeb4079630>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb4079a58>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb40845f8>,\n",
       " <keras.layers.core.Activation at 0x7faeb40de710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb4162c18>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb40bb9e8>,\n",
       " <keras.layers.core.Activation at 0x7faeb40b76d8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae947d0da0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae947e8eb8>,\n",
       " <keras.layers.merge.Add at 0x7fae947e2a90>,\n",
       " <keras.layers.core.Activation at 0x7fae947f8da0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae947f85f8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae947eff28>,\n",
       " <keras.layers.core.Activation at 0x7fae9477e128>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9477ecf8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae94794e48>,\n",
       " <keras.layers.core.Activation at 0x7fae9479a9b0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae947a2f28>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae947399e8>,\n",
       " <keras.layers.merge.Add at 0x7fae947392b0>,\n",
       " <keras.layers.core.Activation at 0x7fae94794da0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94794be0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae947a2860>,\n",
       " <keras.layers.core.Activation at 0x7fae947a2320>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae947ef208>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae947d9d30>,\n",
       " <keras.layers.core.Activation at 0x7fae947d99e8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb410d5c0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb403e978>,\n",
       " <keras.layers.merge.Add at 0x7faeb40a9e80>,\n",
       " <keras.layers.core.Activation at 0x7faeb4058d68>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9475e1d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae947692b0>,\n",
       " <keras.layers.core.Activation at 0x7fae94777470>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94707d68>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae94707780>,\n",
       " <keras.layers.core.Activation at 0x7fae947094a8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9475ada0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae947097f0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae94742e48>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae94725c88>,\n",
       " <keras.layers.merge.Add at 0x7fae9472b438>,\n",
       " <keras.layers.core.Activation at 0x7fae946ba908>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae946baac8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9472b048>,\n",
       " <keras.layers.core.Activation at 0x7fae94725dd8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94709908>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae947771d0>,\n",
       " <keras.layers.core.Activation at 0x7fae94709b70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb4070860>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae947e2fd0>,\n",
       " <keras.layers.merge.Add at 0x7fae947b99b0>,\n",
       " <keras.layers.core.Activation at 0x7fae947944a8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae946c2278>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae947aa7b8>,\n",
       " <keras.layers.core.Activation at 0x7fae946d3320>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae946d3b38>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae946e6cf8>,\n",
       " <keras.layers.core.Activation at 0x7fae946ed860>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae946f4ac8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae94681d30>,\n",
       " <keras.layers.merge.Add at 0x7fae94681470>,\n",
       " <keras.layers.core.Activation at 0x7fae9469ec88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9469ed30>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae946a6438>,\n",
       " <keras.layers.core.Activation at 0x7fae946a6780>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae946ae9b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9463b160>,\n",
       " <keras.layers.core.Activation at 0x7fae946ae470>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94696358>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae946e6358>,\n",
       " <keras.layers.merge.Add at 0x7fae946edd30>,\n",
       " <keras.layers.core.Activation at 0x7faeb4079a20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae947d9c88>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae947b9c50>,\n",
       " <keras.layers.core.Activation at 0x7fae94769780>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae946dd710>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae94734400>,\n",
       " <keras.layers.core.Activation at 0x7fae94641518>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94654fd0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9466add8>,\n",
       " <keras.layers.merge.Add at 0x7fae9466a518>,\n",
       " <keras.layers.core.Activation at 0x7fae945fac50>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae945fa978>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae94604668>,\n",
       " <keras.layers.core.Activation at 0x7fae94604940>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9460ba58>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9460be48>,\n",
       " <keras.layers.core.Activation at 0x7fae9461d860>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94621be0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae945bf278>,\n",
       " <keras.layers.merge.Add at 0x7fae945bfef0>,\n",
       " <keras.layers.core.Activation at 0x7fae9461dcf8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9461d198>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae945bf630>,\n",
       " <keras.layers.core.Activation at 0x7fae9460b128>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94671550>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae94654438>,\n",
       " <keras.layers.core.Activation at 0x7fae9465a4a8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae947776a0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae946ed9e8>,\n",
       " <keras.layers.merge.Add at 0x7fae9467bba8>,\n",
       " <keras.layers.core.Activation at 0x7fae945d8cf8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae945d8be0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae945e14a8>,\n",
       " <keras.layers.core.Activation at 0x7fae945e1f28>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae945ea908>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae945ea710>,\n",
       " <keras.layers.core.Activation at 0x7fae9457a748>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94581c88>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae94590ef0>,\n",
       " <keras.layers.merge.Add at 0x7fae94598b38>,\n",
       " <keras.layers.core.Activation at 0x7fae945a6160>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae945a6eb8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae945af6d8>,\n",
       " <keras.layers.core.Activation at 0x7fae945af908>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae945b79e8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb40b39e8>,\n",
       " <keras.layers.core.Activation at 0x7faeb420cf28>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb4121860>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb403e278>,\n",
       " <keras.layers.merge.Add at 0x7fae947195f8>,\n",
       " <keras.layers.core.Activation at 0x7faeb415da20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae947a2198>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae94777b00>,\n",
       " <keras.layers.core.Activation at 0x7faeb408acf8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae945983c8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae945b7e10>,\n",
       " <keras.layers.core.Activation at 0x7fae945a6e10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae946babe0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb40ca5f8>,\n",
       " <keras.layers.merge.Add at 0x7faeb40dee10>,\n",
       " <keras.layers.core.Activation at 0x7faeb41ece48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb41eca58>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb406aba8>,\n",
       " <keras.layers.core.Activation at 0x7fae9457af28>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9457ac18>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae945e1a20>,\n",
       " <keras.layers.core.Activation at 0x7fae945d8978>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9469e9e8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae946ddf28>,\n",
       " <keras.layers.merge.Add at 0x7fae947aaf60>,\n",
       " <keras.layers.core.Activation at 0x7fae9469eba8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae945d8080>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb416c860>,\n",
       " <keras.layers.core.Activation at 0x7fae945f5b00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae945811d0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae947396d8>,\n",
       " <keras.layers.core.Activation at 0x7fae947420b8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae945af828>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb403e6d8>,\n",
       " <keras.layers.merge.Add at 0x7fae947d9080>,\n",
       " <keras.layers.core.Activation at 0x7fae94734a58>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7faeb40793c8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9479add8>,\n",
       " <keras.layers.core.Activation at 0x7fae94604320>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94654668>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae94663f28>,\n",
       " <keras.layers.core.Activation at 0x7fae9466af98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94621c18>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae94636668>,\n",
       " <keras.layers.merge.Add at 0x7fae944cf1d0>,\n",
       " <keras.layers.core.Activation at 0x7fae944dfc18>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae944df898>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae944e75c0>,\n",
       " <keras.layers.core.Activation at 0x7fae944e7dd8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae944ef978>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae946364e0>,\n",
       " <keras.layers.core.Activation at 0x7fae9461de10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9465a978>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7faeb40924e0>,\n",
       " <keras.layers.merge.Add at 0x7fae94590550>,\n",
       " <keras.layers.core.Activation at 0x7fae946ed6a0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae945d8400>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae946a6710>,\n",
       " <keras.layers.core.Activation at 0x7fae946ba8d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9447af28>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9447a438>,\n",
       " <keras.layers.core.Activation at 0x7fae94494710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9449cac8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae944b7080>,\n",
       " <keras.layers.merge.Add at 0x7fae944b76a0>,\n",
       " <keras.layers.core.Activation at 0x7fae94443748>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94443d68>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9444bda0>,\n",
       " <keras.layers.core.Activation at 0x7fae94443518>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94453f28>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae944677b8>,\n",
       " <keras.layers.core.Activation at 0x7fae94474898>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94474160>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9445d9b0>,\n",
       " <keras.layers.merge.Add at 0x7fae944b7c88>,\n",
       " <keras.layers.core.Activation at 0x7fae944b7cf8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae944a1d68>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9449c3c8>,\n",
       " <keras.layers.core.Activation at 0x7fae9448b4e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94739828>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae946542b0>,\n",
       " <keras.layers.core.Activation at 0x7fae94641e48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae943fefd0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae943fe438>,\n",
       " <keras.layers.merge.Add at 0x7fae9441a6d8>,\n",
       " <keras.layers.core.Activation at 0x7fae9441af98>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94421828>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9442a908>,\n",
       " <keras.layers.core.Activation at 0x7fae94421e10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94430b70>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae943cc1d0>,\n",
       " <keras.layers.core.Activation at 0x7fae943cc5c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae943dbeb8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae943dba90>,\n",
       " <keras.layers.merge.Add at 0x7fae943e69b0>,\n",
       " <keras.layers.core.Activation at 0x7fae943ec550>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae943f3c88>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9437cd68>,\n",
       " <keras.layers.core.Activation at 0x7fae943f3710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae943cc048>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9442aa58>,\n",
       " <keras.layers.core.Activation at 0x7fae94430198>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94641a58>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9459f668>,\n",
       " <keras.layers.merge.Add at 0x7fae94410c88>,\n",
       " <keras.layers.core.Activation at 0x7fae9448b588>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9444b860>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9448b550>,\n",
       " <keras.layers.core.Activation at 0x7fae943825f8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94398860>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae943afc18>,\n",
       " <keras.layers.core.Activation at 0x7fae943a8e10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9433fe10>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9433f0f0>,\n",
       " <keras.layers.merge.Add at 0x7fae943485f8>,\n",
       " <keras.layers.core.Activation at 0x7fae94348278>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9435b588>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9435d748>,\n",
       " <keras.layers.core.Activation at 0x7fae9435d668>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae943699b0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae943026a0>,\n",
       " <keras.layers.core.Activation at 0x7fae94302400>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9435bba8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9435d7b8>,\n",
       " <keras.layers.merge.Add at 0x7fae94348d30>,\n",
       " <keras.layers.core.Activation at 0x7fae94348b00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae943afeb8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae943a05f8>,\n",
       " <keras.layers.core.Activation at 0x7fae94398198>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94382a90>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae943ba550>,\n",
       " <keras.layers.core.Activation at 0x7fae943c53c8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94382c88>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae9431e2b0>,\n",
       " <keras.layers.merge.Add at 0x7fae9432f5c0>,\n",
       " <keras.layers.core.Activation at 0x7fae9432fef0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae942bb710>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae942c07f0>,\n",
       " <keras.layers.core.Activation at 0x7fae942c0b70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae942c4a58>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae942d9f60>,\n",
       " <keras.layers.core.Activation at 0x7fae942dea20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae942eedd8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae942ee978>,\n",
       " <keras.layers.merge.Add at 0x7fae94282ac8>,\n",
       " <keras.layers.core.Activation at 0x7fae94282cf8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae942cc5f8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae94327588>,\n",
       " <keras.layers.core.Activation at 0x7fae94309160>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9431e828>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae943af6a0>,\n",
       " <keras.layers.core.Activation at 0x7fae9433f080>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae942e65c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae942f94e0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae942d9320>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae942a8f98>,\n",
       " <keras.layers.merge.Add at 0x7fae942a5b70>,\n",
       " <keras.layers.core.Activation at 0x7fae9423cdd8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9423cef0>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae942b1860>,\n",
       " <keras.layers.core.Activation at 0x7fae9423f080>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae9423f438>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae94254f28>,\n",
       " <keras.layers.core.Activation at 0x7fae94259400>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94264a58>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae941f94e0>,\n",
       " <keras.layers.merge.Add at 0x7fae941f93c8>,\n",
       " <keras.layers.core.Activation at 0x7fae94209a20>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae94209cf8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae941f9978>,\n",
       " <keras.layers.core.Activation at 0x7fae9426b710>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae942042e8>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae94254240>,\n",
       " <keras.layers.core.Activation at 0x7fae9424dcf8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7fae942a5710>,\n",
       " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7fae94369630>,\n",
       " <keras.layers.merge.Add at 0x7fae943afba8>,\n",
       " <keras.layers.core.Activation at 0x7fae942826a0>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x7fae942c4ba8>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now using the *summary* attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet101 (Functional)       (None, 2048)              42658176  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 42,662,274\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 42,658,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next we compile our model using the **adam** optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch_training = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "25/25 [==============================] - 263s 10s/step - loss: 0.2369 - accuracy: 0.8905 - val_loss: 0.0310 - val_accuracy: 0.9885\n",
      "Epoch 2/2\n",
      "25/25 [==============================] - 256s 10s/step - loss: 0.0294 - accuracy: 0.9908 - val_loss: 0.0212 - val_accuracy: 0.9885\n"
     ]
    }
   ],
   "source": [
    "#fit_history = model.fit_generator(\n",
    "fit_history = model.fit(    \n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now that the model is trained, you are ready to start using it to classify images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandr/.local/lib/python3.6/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save('classifier_resnet_101_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the model file *classifier_resnet_model.h5* apprear in the left directory pane.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by Alex Aklson. I hope you found this lab interesting and educational.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This notebook is part of a course on **Coursera** called *AI Capstone Project with Deep Learning*. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week3\\_LAB1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n",
    "\n",
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                          |\n",
    "| ----------------- | ------- | ---------- | ----------------------------------------------------------- |\n",
    "| 2020-09-18        | 2.0     | Shubham    | Migrated Lab to Markdown and added to course repo in GitLab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "Copyright © 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_medium=dswb&utm_source=bducopyrightlink&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork20647850-2021-01-01&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork20647850-2021-01-01).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
